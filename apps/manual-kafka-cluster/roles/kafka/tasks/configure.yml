---
# configure kafka 

- name: create kafka data and log directory
  file:
    path: "{{ kafka_log_directory }}"
    state: directory
    mode: 0755
    owner: kafka
    group: kafka

- name: backup server and broker properties
  copy:
    src: "{{ kafka_config_directory }}/config/kraft/{{ item.config }}"
    dest: "{{ kafka_config_directory }}/config/kraft/{{ item.config }}.bak"
    owner: kafka
    group: kafka
    mode: 0644
    remote_src: true
  loop:
    - { config: 'server.properties' }
    - { config: 'broker.properties' }

# for servers that are controller and broker roles
- name: updating kafka config for controller and broker
  template:
    src: templates/server.properties.j2
    dest: "{{ kafka_config_directory }}/config/kraft/server.properties"
    owner: kafka
    group: kafka
    mode: 0644
  run_once: true
  delegate_to: "{{ item }}"
  loop: "{{ groups['kafka'] }}"
  loop_control:
    index_var: count
  when: hostvars[groups['kafka'][count]].role == 'controller and broker'

# for servers who are brokers only
- name: updating kafka config for broker only
  template:
    src: templates/broker.properties.j2
    dest: "{{ kafka_config_directory }}/config/kraft/broker.properties"
    owner: kafka
    group: kafka
    mode: 0644
  run_once: true
  delegate_to: "{{ item }}"
  loop: "{{ groups['kafka'] }}"
  loop_control:
    index_var: count
  when: hostvars[groups['kafka'][count]].role == 'broker only'

- name: check existing kafka cluster uuid
  shell:
    cmd: grep -s cluster.id {{ kafka_data_directory }}/data/kraft-combined-logs/meta.properties | cut -f 2 -d = || /bin/true
    removes: "{{ kafka_data_directory}}/data/kraft-combined-logs/meta.properties"
  register: old_cluster_uuid
  run_once: true
  delegate_to: "{{ groups['kafka'][0] }}"

- name: create kafka cluster uuid
  command:
    cmd:  "{{ kafka_bin_directory }}/kafka-storage.sh random-uuid"
    creates: "{{ kafka_data_directory}}/data/kraft-combined-logs/meta.properties"
  register: new_cluster_uuid
  run_once: true
  delegate_to: "{{ groups['kafka'][0] }}"

- name: determine kafka cluster uuid
  set_fact:
    cluster_uuid: "{{ (old_cluster_uuid.changed) | ternary(old_cluster_uuid.stdout, new_cluster_uuid.stdout) }}"
  run_once: true
  delegate_to: "{{ groups['kafka'][0] }}"

- name: format data directory for controller and broker nodes
  command:
    cmd: "{{ kafka_bin_directory }}/kafka-storage.sh format -t {{ cluster_uuid}} -c {{ kafka_config_directory }}/config/kraft/server.properties --ignore-formatted"
  become: true
  become_user: kafka
  run_once: true
  delegate_to: "{{ item }}"
  loop: "{{ groups['kafka'] }}"
  loop_control:
    index_var: count
  when: hostvars[groups['kafka'][count]].role == 'controller and broker'

- name: format data directory broker nodes
  command:
    cmd: "{{ kafka_bin_directory }}/kafka-storage.sh format -t {{ cluster_uuid}} -c {{ kafka_config_directory }}/config/kraft/broker.properties --ignore-formatted"
  become: true
  become_user: kafka
  run_once: true
  delegate_to: "{{ item }}"
  loop: "{{ groups['kafka'] }}"
  loop_control:
    index_var: count
  when: hostvars[groups['kafka'][count]].role == 'broker only'

- name: starting kafka
  systemd:
    name: kafka
    state: started
    enabled: true
    daemon_reload: true
